{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os,cv2,re,random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array , load_img\n",
    "from keras import layers,models,optimizers\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dir = \"../input/train/\"\n",
    "test_dir = \"../input/test/\"\n",
    "train_img_dogs_cat = [train_dir + i for i in os.listdir(train_dir)]#use this f or use whole dataset\n",
    "test_img_dogs_cat = [test_dir + i for i in os.listdir(test_dir)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to sort the image files based on the numeric value in each file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the traning set. Use 1300 images each of cats and dogs instead of all 25000 to speed up the learning process.\n",
    "\n",
    "Sort the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dogs_cat.sort(key = natural_keys)\n",
    "train_img_dogs_cat = train_img_dogs_cat[0:1300] + train_img_dogs_cat[12500 :13800]\n",
    "test_img_dogs_cat.sort(key = natural_keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the images have to be represented in numbers. For this, using the openCV library read and resize the image.\n",
    "\n",
    "Generate labels for the supervised learning set.\n",
    "\n",
    "Below is the helper function to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "\n",
    "def prepare_data(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n",
    "    \n",
    "    for i in list_of_images:\n",
    "        if 'dog' in i:\n",
    "            y.append(1)\n",
    "        elif 'cat' in i:\n",
    "            y.append(0)\n",
    "        #else:\n",
    "            #print('neither cat nor dog name present in images')\n",
    "            \n",
    "    return x, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X and Y using the helper function above\n",
    "\n",
    "Since K.image_data_format() is channel_last, input_shape to the first keras layer will be (img_width, img_height, 3). '3' since it is a color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "X,Y = prepare_data(train_img_dogs_cat)\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set containing 2600 images into 2 parts, training set and validation set. Later, you will see that accuracy and loss on the validation set will also be reported while fitting the model using training set.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val ,y_train, y_val = train_test_split(X,Y,test_size = 0.2 ,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Sequential model from Keras to form the Neural Network. Sequential Model is used to construct simple models with linear stack of layers.\n",
    "\n",
    "More info on Sequential model and Keras in general at https://keras.io/getting-started/sequential-model-guide/ and https://github.com/keras-team/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),input_shape=(img_width,img_height,3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the augmentation configuration we will use for training and validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare generators for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(np.array(X_train),y_train,batch_size = batch_size)\n",
    "validation_generator = train_datagen.flow(np.array(X_val),y_val,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training the model!\n",
    "\n",
    "For better accuracy and lower loss, we are using an epoch of 30. Epoch value can be increased for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 0.7486 - acc: 0.5183 - val_loss: 0.6871 - val_acc: 0.5176\n",
      "Epoch 2/30\n",
      "130/130 [==============================] - 41s 317ms/step - loss: 0.6872 - acc: 0.5596 - val_loss: 0.6486 - val_acc: 0.6190\n",
      "Epoch 3/30\n",
      "130/130 [==============================] - 41s 316ms/step - loss: 0.6680 - acc: 0.6149 - val_loss: 0.6488 - val_acc: 0.6409\n",
      "Epoch 4/30\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 0.6509 - acc: 0.6385 - val_loss: 0.8240 - val_acc: 0.5119\n",
      "Epoch 5/30\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 0.6544 - acc: 0.6452 - val_loss: 0.6830 - val_acc: 0.5972\n",
      "Epoch 6/30\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 0.6319 - acc: 0.6760 - val_loss: 0.6168 - val_acc: 0.6806\n",
      "Epoch 7/30\n",
      "130/130 [==============================] - 41s 317ms/step - loss: 0.6237 - acc: 0.6745 - val_loss: 0.6106 - val_acc: 0.6766\n",
      "Epoch 8/30\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 0.6341 - acc: 0.6841 - val_loss: 0.9033 - val_acc: 0.5873\n",
      "Epoch 9/30\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 0.6131 - acc: 0.6962 - val_loss: 0.6205 - val_acc: 0.6607\n",
      "Epoch 10/30\n",
      "130/130 [==============================] - 41s 317ms/step - loss: 0.6104 - acc: 0.6856 - val_loss: 0.5888 - val_acc: 0.6825\n",
      "Epoch 11/30\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.6074 - acc: 0.6937 - val_loss: 0.7008 - val_acc: 0.5992\n",
      "Epoch 12/30\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 0.6004 - acc: 0.7120 - val_loss: 0.5567 - val_acc: 0.7302\n",
      "Epoch 13/30\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 0.5862 - acc: 0.7207 - val_loss: 0.5903 - val_acc: 0.6964\n",
      "Epoch 14/30\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 0.5885 - acc: 0.7072 - val_loss: 0.5596 - val_acc: 0.6944\n",
      "Epoch 15/30\n",
      "130/130 [==============================] - 41s 319ms/step - loss: 0.5986 - acc: 0.7062 - val_loss: 0.6284 - val_acc: 0.6806\n",
      "Epoch 16/30\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.5870 - acc: 0.7264 - val_loss: 0.6554 - val_acc: 0.6230\n",
      "Epoch 17/30\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.6048 - acc: 0.7183 - val_loss: 1.4377 - val_acc: 0.5714\n",
      "Epoch 18/30\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.6076 - acc: 0.7111 - val_loss: 0.6050 - val_acc: 0.6667\n",
      "Epoch 19/30\n",
      "130/130 [==============================] - 42s 319ms/step - loss: 0.5862 - acc: 0.7101 - val_loss: 0.6200 - val_acc: 0.6349\n",
      "Epoch 20/30\n",
      "130/130 [==============================] - 41s 318ms/step - loss: 0.5903 - acc: 0.7077 - val_loss: 0.5823 - val_acc: 0.7202\n",
      "Epoch 21/30\n",
      "130/130 [==============================] - 42s 322ms/step - loss: 0.6058 - acc: 0.7130 - val_loss: 0.5965 - val_acc: 0.6786\n",
      "Epoch 22/30\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.6062 - acc: 0.7159 - val_loss: 0.5631 - val_acc: 0.7242\n",
      "Epoch 23/30\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.6001 - acc: 0.7062 - val_loss: 0.5797 - val_acc: 0.6726\n",
      "Epoch 24/30\n",
      "130/130 [==============================] - 42s 323ms/step - loss: 0.5960 - acc: 0.7154 - val_loss: 0.6429 - val_acc: 0.6409\n",
      "Epoch 25/30\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 0.5917 - acc: 0.7101 - val_loss: 0.5757 - val_acc: 0.6925\n",
      "Epoch 26/30\n",
      "130/130 [==============================] - 42s 323ms/step - loss: 0.6034 - acc: 0.7019 - val_loss: 0.6242 - val_acc: 0.6587\n",
      "Epoch 27/30\n",
      "130/130 [==============================] - 42s 321ms/step - loss: 0.5687 - acc: 0.7293 - val_loss: 0.6643 - val_acc: 0.6944\n",
      "Epoch 28/30\n",
      "130/130 [==============================] - 42s 319ms/step - loss: 0.5907 - acc: 0.7173 - val_loss: 0.6192 - val_acc: 0.6905\n",
      "Epoch 29/30\n",
      "130/130 [==============================] - 42s 324ms/step - loss: 0.5741 - acc: 0.7298 - val_loss: 0.6550 - val_acc: 0.6726\n",
      "Epoch 30/30\n",
      "130/130 [==============================] - 42s 322ms/step - loss: 0.5640 - acc: 0.7245 - val_loss: 0.5662 - val_acc: 0.7361\n"
     ]
    }
   ],
   "source": [
    "hystory = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch = nb_train_samples // batch_size,\n",
    "                epochs = 30,\n",
    "                validation_data = validation_generator,\n",
    "                validation_steps=nb_validation_samples // batch_size\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = prepare_data(test_img_dogs_cat) #Y_test in this case will be []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 86s 110ms/step\n"
     ]
    }
   ],
   "source": [
    "steps = nb_train_samples // batch_size\n",
    "test_generator = val_datagen.flow(np.array(X_test), batch_size=batch_size)\n",
    "\n",
    "prediction_probabilities = model.predict_generator(test_generator, verbose=1,steps=782)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = range(1, len(test_img_dogs_cat) + 1)\n",
    "solution = pd.DataFrame({\"id\": counter, \"label\":list(prediction_probabilities)})\n",
    "cols = ['label']\n",
    "\n",
    "for col in cols:\n",
    "    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n",
    "\n",
    "solution.to_csv(\"dogsVScats.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
